{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling Models Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import skopt\n",
    "import lightgbm as lgb\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Pre Processing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Balancing Classes\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import *\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Models\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#Hyper para\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Warnings\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from skopt.space import Real, Integer\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import wandb\n",
    "from wandb.integration.xgboost import WandbCallback\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df festures dtypes\n",
    "df_dtypes = {\"PAYMENT_DAY\":\"category\", \"APPLICATION_SUBMISSION_TYPE\":\"category\", \"POSTAL_ADDRESS_TYPE\":\"category\", \"SEX\":\"category\", \"MARITAL_STATUS\":\"category\",\n",
    "             \"STATE_OF_BIRTH\":\"category\", \"CITY_OF_BIRTH\":\"category\", \"NACIONALITY\":\"category\",\t\"RESIDENCIAL_STATE\":\"category\",\"RESIDENCIAL_CITY\":\"category\",\n",
    "             \"RESIDENCIAL_BOROUGH\":\"category\", \"FLAG_RESIDENCIAL_PHONE\":\"category\", \"RESIDENCIAL_PHONE_AREA_CODE\":\"category\", \"RESIDENCE_TYPE\":\"category\",\n",
    "             \"FLAG_EMAIL\":\"category\", \"FLAG_VISA\":\"category\", \"FLAG_MASTERCARD\":\"category\",\t\"FLAG_DINERS\":\"category\",\"FLAG_AMERICAN_EXPRESS\":\"category\",\"FLAG_OTHER_CARDS\":\"category\", \n",
    "             \"QUANT_BANKING_ACCOUNTS\":\"category\",\"QUANT_SPECIAL_BANKING_ACCOUNTS\":\"category\",\"QUANT_CARS\":\"category\",\"COMPANY\":\"category\",\n",
    "             \"PROFESSIONAL_STATE\":\"category\",\"FLAG_PROFESSIONAL_PHONE\":\"category\",\"PROFESSIONAL_PHONE_AREA_CODE\":\"category\",\"PROFESSION_CODE\":\"category\",\"OCCUPATION_TYPE\":\"category\",\n",
    "             \"PRODUCT\":\"category\",\"RESIDENCIAL_ZIP_3\":\"category\",\"PROFESSIONAL_ZIP_3\":\"category\", \"QUANT_DEPENDANTS\":\"category\",\"AGE\":\"float64\",\"total_cards\" : \"category\", \"TARGET_LABEL_BAD=1\":\"object\",\n",
    "             \"MONTHS_IN_RESIDENCE\":\"category\", \"PERSONAL_MONTHLY_INCOME\":\"float\", \"OTHER_INCOMES\":\"category\", \"MONTHS_IN_THE_JOB\":\"category\",\"PERSONAL_ASSETS_VALUE\":\"category\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import DF\n",
    "df = pd.read_csv(r\"C:\\Users\\59898\\Desktop\\proyect\\model\\data\\Clean_data\\data01.csv\",  encoding = \"ISO-8859-1\", sep = \",\", dtype=df_dtypes, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask to categorical and numeric columns\n",
    "numerical_mask = (df.dtypes == \"float64\")\n",
    "categorical_mask = (df.dtypes == \"category\")\n",
    "\n",
    "# List with cat and num cols\n",
    "numeric_cols  = df.columns[numerical_mask].tolist()\n",
    "categorical_cols = df.columns[categorical_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed\n",
    "seed = 123\n",
    "\n",
    "# Split data into label and features\n",
    "X = df.loc[:, df.columns != 'TARGET_LABEL_BAD=1']\n",
    "y = df[\"TARGET_LABEL_BAD=1\"].astype(\"int64\")\n",
    "\n",
    "# Train / test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = seed, stratify = y)\n",
    "# Validation / Train Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state = seed, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing pipeline\n",
    "num_transformer = Pipeline(\n",
    "                            steps = [\n",
    "                                        (\"inputer\", SimpleImputer(missing_values= np.nan,\n",
    "                                                                  strategy = \"median\")),\n",
    "                                        (\"scaler\", RobustScaler())\n",
    "                                    ])\n",
    "cat_transformer = Pipeline(\n",
    "                            steps = [\n",
    "                                        (\"cat_inputer\", SimpleImputer(missing_values= np.nan,\n",
    "                                                                      strategy = \"most_frequent\")),\n",
    "                                        (\"encoder\", OneHotEncoder(drop=\"if_binary\",\n",
    "                                                                  handle_unknown=\"ignore\",\n",
    "                                                                  sparse=False))\n",
    "                                    ])\n",
    "\n",
    "# Ensemble Transformers\n",
    "pre_processor = ColumnTransformer(\n",
    "                            transformers= [\n",
    "                                        (\"num\", num_transformer, numeric_cols),\n",
    "                                        (\"cat\", cat_transformer, categorical_cols)\n",
    "                                        ],\n",
    "                            verbose_feature_names_out = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply  preprocessor to cat and num cols\n",
    "\n",
    "# Train\n",
    "X_pre_train = pre_processor.fit_transform(X= X_train)\n",
    "\n",
    "# Validation\n",
    "X_pre_val = pre_processor.transform(X=X_val)\n",
    "\n",
    "# Test\n",
    "X_pre_test = pre_processor.transform(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTEENN \n",
    "\n",
    "we can see that SMOTEENN give us the best values so we test that method with our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN X varibales\n",
    "smoteenn  = SMOTEENN(random_state=7)\n",
    "X_over_smtee, y_over_smotee = smoteenn.fit_resample(X_pre_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(352,)),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])\n",
    "\n",
    "model.fit(X_over_smtee, y_over_smotee, epochs=25, batch_size=16)\n",
    "test_loss, test_acc = model.evaluate(X_pre_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfederto\u001b[0m (\u001b[33manyone-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(): \n",
    "#       # Set default configurations (Defaults will be overwritten during sweep)\n",
    "#   config_defaults = {\n",
    "      \n",
    "#       'max_depth': 3, \n",
    "#       'min_child_weight': 1,\n",
    "#       'n_estimators': 1500,\n",
    "#       'learning_rate' : 0.3,\n",
    "#       'colsample_bytree' : 0.3,\n",
    "#       \"subsample\" : 0.3,\n",
    "#       \"reg_alpha\" : 0,\n",
    "#       \"reg_lambda\" : 0,\n",
    "#       \"objective\" : \"binary:logistic\",\n",
    "#       \"random_state\" : 123\n",
    "      \n",
    "#   }\n",
    "\n",
    "#   # Start W&B\n",
    "#   wandb.init(config=config_defaults)\n",
    "#   config = wandb.config\n",
    "\n",
    "#   # Fit regression model on train set\n",
    "#   model = xgb.XGBClassifier(\n",
    "#       max_depth=config.max_depth, \n",
    "#       min_child_weight=config.min_child_weight,\n",
    "#       n_estimators=config.n_estimators,\n",
    "#       learning_rate=config.learning_rate,\n",
    "#       colsample_bytree=config.colsample_bytree,\n",
    "#       subsample=config.subsample,\n",
    "#       reg_alpha=config.reg_alpha,\n",
    "#       reg_lambda=config.reg_lambda,\n",
    "#       objective=config.objective,\n",
    "#       seed=config.random_state\n",
    "#     )\n",
    "  \n",
    "#   model.fit(X_over_smtee, y_over_smotee)\n",
    "#   # Predict on test set\n",
    "#   y_pred = model.predict_proba(X_pre_val)\n",
    "#   y_pred_t = model.predict_proba(X_pre_test)\n",
    "#   # Evaluate predictions\n",
    "#   auc_val = roc_auc_score(y_val,  y_pred[:, 1])\n",
    "#   auc_test = roc_auc_score(y_test,  y_pred_t[:, 1])\n",
    "#   print(f\"AUC: {round(auc_val, 4)}\")\n",
    "\n",
    "#   # Log model performance metrics to W&B\n",
    "#   wandb.log({\"auc_val\": auc_val, \"auc_test\": auc_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model():\n",
    "#       # Set default configurations (Defaults will be overwritten during sweep)\n",
    "#   config_defaults = {\n",
    "      \n",
    "#       'n_estimators': 1500,\n",
    "#       'learning_rate' : 0.1,\n",
    "#       \"penalty\" : 0,\n",
    "#       \"random_state\" : 123\n",
    "      \n",
    "#   }\n",
    "\n",
    "#   # Start W&B\n",
    "#   wandb.init(config=config_defaults)\n",
    "#   config = wandb.config\n",
    "\n",
    "#   # Fit regression model on train set\n",
    "#   model = SGDClassifier(\n",
    "#                         random_state = config.random_state,\n",
    "#                         loss = \"log_loss\",\n",
    "#                         verbose = 0,\n",
    "#                         max_iter  =config.n_estimators,\n",
    "#                         penalty = config.penalty,\n",
    "#                         alpha= config.learning_rate)\n",
    "  \n",
    "#   model.fit(X_over_smtee, y_over_smotee)\n",
    "#   # Predict on test set\n",
    "#   y_pred = model.predict_proba(X_pre_val)\n",
    "#   y_pred_t = model.predict_proba(X_pre_test)\n",
    "#   # Evaluate predictions\n",
    "#   auc_val = roc_auc_score(y_val,  y_pred[:, 1])\n",
    "#   auc_test = roc_auc_score(y_test,  y_pred_t[:, 1])\n",
    "#   print(f\"AUC: {round(auc_val, 4)}\")\n",
    "\n",
    "#   # Log model performance metrics to W&B\n",
    "#   wandb.log({\"auc_val\": auc_val, \"auc_test\": auc_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_configs = { \n",
    "#     \"method\": \"bayes\",\n",
    "#     \"metric\": {\n",
    "#         \"name\": \"auc_val\",\n",
    "#         \"goal\": \"maximize\"\n",
    "#     },\n",
    "#     \"parameters\": {\n",
    "#         \"max_depth\": {\n",
    "#             \"values\": [2,3,4]\n",
    "#         },\n",
    "#         \"min_child_weight\": {\n",
    "#             \"values\": [0,3,5,7,10]\n",
    "#         },\n",
    "#         \"n_estimators\": {\n",
    "#             \"values\": [5000,4000,3000]\n",
    "        \n",
    "#         },\n",
    "#         'learning_rate' : {\n",
    "#             \"values\" : [0.05, 0.025, 0.01, 0.005]\n",
    "#         },\n",
    "#         'colsample_bytree': {\n",
    "#             \"values\" : [0.3, 0.5, 0.7, 0.9]\n",
    "#         },\n",
    "#         \"subsample\" : {\n",
    "#             \"values\" : [0.3, 0.5, 0.7, 0.9]\n",
    "#         },\n",
    "#         \"reg_alpha\" : {\n",
    "#             \"values\" : [0,1,2,3,4,5]\n",
    "#         },\n",
    "#         \"reg_lambda\" : {\n",
    "#             \"values\" : [0,1,2,3,4,5]\n",
    "#         },\n",
    "#         \"random_state\"  : {\n",
    "#             \"values\" : [123]\n",
    "#         },\n",
    "#         \"objective\" : {\n",
    "#             \"values\" : [\"binary:logistic\"]\n",
    "#         }\n",
    "#     }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_configs = {\n",
    "#     \"method\": \"bayes\",\n",
    "#     \"metric\": {\n",
    "#         \"name\": \"auc_val\",\n",
    "#         \"goal\": \"maximize\"\n",
    "#     },\n",
    "#     \"parameters\": {\n",
    "\n",
    "#         \"penalty\": {\n",
    "#             \"values\": [\"l1\", \"l2\"]\n",
    "#         },\n",
    "#         \"n_estimators\": {\n",
    "#             \"values\": [3000, 2500, 2000, 1500]\n",
    "        \n",
    "#         },\n",
    "#         'learning_rate' : {\n",
    "#             \"values\" : [0.05, 0.025, 0.01, 0.005]\n",
    "       \n",
    "#         }\n",
    "#     }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep=sweep_configs, project=\"credit\")\n",
    "# wandb.agent(sweep_id=sweep_id, function=train_model, count=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f0391182499eb7d1c5c751ec44e92775962a06825ffcc94383a3e33c4ce1168"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
